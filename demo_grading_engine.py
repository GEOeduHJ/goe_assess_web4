#!/usr/bin/env python3
"""
Demonstration script for the Sequential Grading Engine.

This script shows how to use the grading engine with sample data.
"""

import time
from services.grading_engine import SequentialGradingEngine, GradingStatus
from services.llm_service import GradingType
from models.student_model import Student
from models.rubric_model import Rubric, EvaluationElement, EvaluationCriteria


def create_sample_data():
    """Create sample students and rubric for demonstration."""
    
    # Create sample students
    students = [
        Student(
            name="ê¹€ì² ìˆ˜", 
            class_number="1-1", 
            answer="í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ë‹¤. ì„œìš¸ì€ í•œê°• ìœ ì—­ì— ìœ„ì¹˜í•˜ë©° ì¡°ì„ ì‹œëŒ€ë¶€í„° ìˆ˜ë„ ì—­í• ì„ í•´ì™”ë‹¤."
        ),
        Student(
            name="ì´ì˜í¬", 
            class_number="1-2", 
            answer="ë¶€ì‚°ì€ í•œêµ­ì˜ ì œ2ì˜ ë„ì‹œì´ë‹¤. ë‚¨ë™ìª½ í•´ì•ˆì— ìœ„ì¹˜í•˜ë©° ì¤‘ìš”í•œ í•­êµ¬ë„ì‹œì´ë‹¤."
        ),
        Student(
            name="ë°•ë¯¼ìˆ˜", 
            class_number="1-3", 
            answer="ì œì£¼ë„ëŠ” í•œêµ­ì˜ ë‚¨ìª½ì— ìœ„ì¹˜í•œ í™”ì‚°ì„¬ì´ë‹¤. í•œë¼ì‚°ì´ ìˆìœ¼ë©° ê´€ê´‘ì§€ë¡œ ìœ ëª…í•˜ë‹¤."
        ),
        Student(
            name="ìµœì§€í˜œ", 
            class_number="1-4", 
            answer="ì¸ì²œì€ ì„œìš¸ ê·¼ì²˜ì— ìˆëŠ” í•­êµ¬ë„ì‹œì´ë‹¤."
        ),
        Student(
            name="ì •ë¯¼í˜¸", 
            class_number="1-5", 
            answer="ëŒ€êµ¬ëŠ” ê²½ìƒë¶ë„ì— ìœ„ì¹˜í•œ ë„ì‹œì´ë‹¤."
        )
    ]
    
    # Create sample rubric
    rubric = Rubric(name="ì§€ë¦¬ ê¸°ë³¸ ì§€ì‹ í‰ê°€")
    
    # ì •í™•ì„± í‰ê°€ ìš”ì†Œ
    accuracy_element = EvaluationElement(name="ì •í™•ì„±")
    accuracy_element.add_criteria(5, "ì™„ì „íˆ ì •í™•í•œ ì§€ë¦¬ì  ì‚¬ì‹¤")
    accuracy_element.add_criteria(3, "ëŒ€ì²´ë¡œ ì •í™•í•˜ë‚˜ ì¼ë¶€ ë¶€ì •í™•í•œ ë‚´ìš©")
    accuracy_element.add_criteria(1, "ë¶€ì •í™•í•œ ë‚´ìš©ì´ ë§ìŒ")
    accuracy_element.add_criteria(0, "ì™„ì „íˆ ë¶€ì •í™•í•˜ê±°ë‚˜ ë‹µë³€ ì—†ìŒ")
    
    # ì™„ì„±ë„ í‰ê°€ ìš”ì†Œ
    completeness_element = EvaluationElement(name="ì™„ì„±ë„")
    completeness_element.add_criteria(5, "ìƒì„¸í•˜ê³  ì™„ì „í•œ ì„¤ëª…")
    completeness_element.add_criteria(3, "ê¸°ë³¸ì ì¸ ì„¤ëª…ì€ í¬í•¨")
    completeness_element.add_criteria(1, "ë§¤ìš° ê°„ë‹¨í•œ ì„¤ëª…")
    completeness_element.add_criteria(0, "ì„¤ëª… ë¶€ì¡± ë˜ëŠ” ë‹µë³€ ì—†ìŒ")
    
    rubric.add_element(accuracy_element)
    rubric.add_element(completeness_element)
    
    return students, rubric


def demo_progress_tracking():
    """Demonstrate progress tracking capabilities."""
    print("=== Sequential Grading Engine Demo ===\n")
    
    # Create sample data
    students, rubric = create_sample_data()
    
    print(f"ğŸ“š Created {len(students)} sample students:")
    for i, student in enumerate(students, 1):
        print(f"  {i}. {student.name} ({student.class_number}): {student.answer[:50]}...")
    
    print(f"\nğŸ“‹ Created rubric '{rubric.name}' with {len(rubric.elements)} evaluation elements:")
    for element in rubric.elements:
        print(f"  - {element.name} (max: {element.max_score} points)")
    
    # Create grading engine
    engine = SequentialGradingEngine()
    
    # Set up progress tracking
    print("\nğŸ”§ Setting up progress tracking...")
    
    def progress_callback(progress):
        print(f"ğŸ“Š Progress: {progress.completed_students + progress.failed_students}/{progress.total_students} "
              f"({progress.progress_percentage:.1f}%) - "
              f"âœ… {progress.completed_students} completed, "
              f"âŒ {progress.failed_students} failed")
        
        if progress.average_processing_time > 0:
            print(f"   â±ï¸  Average time: {progress.average_processing_time:.2f}s per student")
            if progress.estimated_completion_time:
                remaining_time = progress.estimated_completion_time - time.time()
                if remaining_time > 0:
                    print(f"   ğŸ•’ Estimated completion: {remaining_time:.1f}s remaining")
    
    def student_completed_callback(status):
        if status.status == GradingStatus.COMPLETED:
            print(f"âœ… Completed: {status.student.name} "
                  f"(Score: {status.result.total_score}/{status.result.total_max_score}, "
                  f"Time: {status.processing_time:.2f}s)")
        elif status.status == GradingStatus.FAILED:
            print(f"âŒ Failed: {status.student.name} "
                  f"(Attempts: {status.attempt_count}, "
                  f"Error: {status.error_message})")
    
    def error_callback(message, exception):
        print(f"ğŸš¨ Error: {message} - {exception}")
    
    engine.set_progress_callback(progress_callback)
    engine.set_student_completed_callback(student_completed_callback)
    engine.set_error_callback(error_callback)
    
    # Validate setup
    print("\nğŸ” Validating grading setup...")
    validation = engine.validate_grading_setup(
        students=students,
        rubric=rubric,
        model_type="gemini",
        grading_type=GradingType.DESCRIPTIVE
    )
    
    if validation["valid"]:
        print("âœ… Setup validation passed!")
        if validation["warnings"]:
            for warning in validation["warnings"]:
                print(f"âš ï¸  Warning: {warning}")
    else:
        print("âŒ Setup validation failed:")
        for error in validation["errors"]:
            print(f"   - {error}")
        return
    
    # Note: This demo doesn't actually call the LLM APIs
    print("\nğŸ“ Note: This demo shows the grading engine structure.")
    print("   To run actual grading, you would need valid API keys in .env file.")
    print("   The engine would call:")
    print("   - Google Gemini API for text/image analysis")
    print("   - Groq API for text-only analysis")
    
    # Show what the grading process would look like
    print(f"\nğŸš€ Sequential grading process would:")
    print(f"   1. Process {len(students)} students one by one")
    print(f"   2. Generate structured prompts with rubric and student answers")
    print(f"   3. Call selected LLM API for each student")
    print(f"   4. Parse and validate JSON responses")
    print(f"   5. Handle retries for failed API calls (max {engine.llm_service.validate_api_availability()})")
    print(f"   6. Track timing and progress for each student")
    print(f"   7. Generate comprehensive grading summary")
    
    # Show summary structure
    print(f"\nğŸ“ˆ Grading summary would include:")
    print(f"   - Total/completed/failed student counts")
    print(f"   - Success rate and average processing time")
    print(f"   - Individual student results with scores and feedback")
    print(f"   - Detailed error information for failed attempts")
    
    print(f"\nğŸ¯ Key features demonstrated:")
    print(f"   âœ… Sequential processing with progress tracking")
    print(f"   âœ… Real-time progress callbacks and updates")
    print(f"   âœ… Automatic retry mechanism for API failures")
    print(f"   âœ… Comprehensive error handling and logging")
    print(f"   âœ… Detailed timing and performance metrics")
    print(f"   âœ… Validation and setup verification")
    print(f"   âœ… Cancellation support for long-running processes")


def demo_api_availability():
    """Demonstrate API availability checking."""
    print("\n=== API Availability Check ===")
    
    engine = SequentialGradingEngine()
    api_status = engine.llm_service.validate_api_availability()
    
    print("ğŸ”Œ API Status:")
    for api_name, available in api_status.items():
        status_icon = "âœ…" if available else "âŒ"
        status_text = "Available" if available else "Not Available"
        print(f"   {status_icon} {api_name.title()}: {status_text}")
    
    if not any(api_status.values()):
        print("\nâš ï¸  No APIs are available. To use the grading engine:")
        print("   1. Create a .env file in the project root")
        print("   2. Add your API keys:")
        print("      GOOGLE_API_KEY=your_gemini_api_key")
        print("      GROQ_API_KEY=your_groq_api_key")
        print("   3. Restart the application")


if __name__ == "__main__":
    try:
        demo_progress_tracking()
        demo_api_availability()
        
        print("\nğŸ‰ Demo completed successfully!")
        print("   The Sequential Grading Engine is ready for use.")
        
    except Exception as e:
        print(f"\nğŸ’¥ Demo failed with error: {e}")
        print("   This is expected if API keys are not configured.")