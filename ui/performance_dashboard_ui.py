"""
Performance Dashboard UI for Geography Auto-Grading System

This module provides UI components for displaying performance metrics,
system status, and optimization controls.
"""

import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
from typing import Dict, Any, List
import pandas as pd

from utils.performance_optimizer import performance_monitor, get_performance_dashboard
from config import config


class PerformanceDashboardUI:
    """UI components for performance monitoring and optimization."""
    
    def __init__(self):
        """Initialize performance dashboard UI."""
        self.refresh_interval = 5  # seconds
    
    def render_performance_dashboard(self):
        """Render the main performance dashboard."""
        st.markdown("## ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ")
        
        # Get performance data
        perf_data = get_performance_dashboard()
        
        if "error" in perf_data:
            st.warning("âš ï¸ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸš€ ëª¨ë‹ˆí„°ë§ ì‹œì‘", type="primary"):
                    from utils.performance_optimizer import start_performance_monitoring
                    start_performance_monitoring()
                    st.success("âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
            
            with col2:
                if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
                    st.rerun()
            
            return
        
        # Performance overview cards
        self.render_performance_overview(perf_data)
        
        # Detailed metrics
        col1, col2 = st.columns(2)
        
        with col1:
            self.render_memory_metrics(perf_data)
            self.render_cache_metrics(perf_data)
        
        with col2:
            self.render_api_metrics(perf_data)
            self.render_ui_metrics(perf_data)
        
        # Recommendations
        self.render_recommendations(perf_data)
        
        # Control panel
        self.render_control_panel()
    
    def render_performance_overview(self, perf_data: Dict[str, Any]):
        """Render performance overview cards."""
        st.markdown("### ğŸ“ˆ ì„±ëŠ¥ ê°œìš”")
        
        current_metrics = perf_data.get("current_metrics", {})
        memory_info = perf_data.get("memory", {})
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            memory_usage = memory_info.get("current_mb", 0)
            memory_threshold = memory_info.get("threshold_mb", config.MAX_MEMORY_USAGE_MB)
            memory_percent = (memory_usage / memory_threshold) * 100
            
            # Color based on usage
            if memory_percent < 70:
                color = "normal"
            elif memory_percent < 90:
                color = "warning"
            else:
                color = "error"
            
            st.metric(
                label="ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰",
                value=f"{memory_usage:.0f}MB",
                delta=f"{memory_percent:.1f}% of limit"
            )
            
            if color == "error":
                st.error("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë†’ìŒ")
            elif color == "warning":
                st.warning("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì£¼ì˜")
        
        with col2:
            cpu_usage = current_metrics.get("cpu_usage_percent", 0)
            st.metric(
                label="ğŸ–¥ï¸ CPU ì‚¬ìš©ë¥ ",
                value=f"{cpu_usage:.1f}%"
            )
            
            if cpu_usage > 80:
                st.error("âš ï¸ CPU ì‚¬ìš©ë¥  ë†’ìŒ")
            elif cpu_usage > 60:
                st.warning("âš ï¸ CPU ì‚¬ìš©ë¥  ì£¼ì˜")
        
        with col3:
            api_stats = perf_data.get("api_performance", {})
            api_calls = api_stats.get("total_calls", 0)
            success_rate = api_stats.get("success_rate", 0)
            
            st.metric(
                label="ğŸ”— API í˜¸ì¶œ",
                value=f"{api_calls}íšŒ",
                delta=f"{success_rate:.1f}% ì„±ê³µë¥ "
            )
            
            if success_rate < 90:
                st.error("âš ï¸ API ì„±ê³µë¥  ë‚®ìŒ")
            elif success_rate < 95:
                st.warning("âš ï¸ API ì„±ê³µë¥  ì£¼ì˜")
        
        with col4:
            cache_stats = perf_data.get("cache_stats", {})
            hit_rate = cache_stats.get("hit_rate", 0)
            
            st.metric(
                label="ğŸ’¨ ìºì‹œ ì ì¤‘ë¥ ",
                value=f"{hit_rate:.1f}%"
            )
            
            if hit_rate < 20:
                st.warning("âš ï¸ ìºì‹œ íš¨ìœ¨ì„± ë‚®ìŒ")
    
    def render_memory_metrics(self, perf_data: Dict[str, Any]):
        """Render memory usage metrics."""
        st.markdown("#### ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰")
        
        memory_info = perf_data.get("memory", {})
        
        if memory_info:
            # Memory usage chart
            fig = go.Figure(go.Indicator(
                mode="gauge+number+delta",
                value=memory_info.get("current_mb", 0),
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"},
                delta={'reference': memory_info.get("avg_mb", 0)},
                gauge={
                    'axis': {'range': [None, memory_info.get("threshold_mb", 1024)]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, memory_info.get("threshold_mb", 1024) * 0.7], 'color': "lightgray"},
                        {'range': [memory_info.get("threshold_mb", 1024) * 0.7, memory_info.get("threshold_mb", 1024) * 0.9], 'color': "yellow"},
                        {'range': [memory_info.get("threshold_mb", 1024) * 0.9, memory_info.get("threshold_mb", 1024)], 'color': "red"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': memory_info.get("threshold_mb", 1024)
                    }
                }
            ))
            
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
            
            # Memory details
            with st.expander("ğŸ“Š ë©”ëª¨ë¦¬ ìƒì„¸ ì •ë³´"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**í˜„ì¬ ì‚¬ìš©ëŸ‰:** {memory_info.get('current_mb', 0):.1f}MB")
                    st.write(f"**í‰ê·  ì‚¬ìš©ëŸ‰:** {memory_info.get('avg_mb', 0):.1f}MB")
                with col2:
                    st.write(f"**ìµœëŒ€ ì‚¬ìš©ëŸ‰:** {memory_info.get('max_mb', 0):.1f}MB")
                    st.write(f"**ì„ê³„ê°’:** {memory_info.get('threshold_mb', 0):.1f}MB")
    
    def render_api_metrics(self, perf_data: Dict[str, Any]):
        """Render API performance metrics."""
        st.markdown("#### ğŸ”— API ì„±ëŠ¥")
        
        api_stats = perf_data.get("api_performance", {})
        
        if api_stats and "error" not in api_stats:
            # API response time chart
            response_times = [
                api_stats.get("min_duration", 0),
                api_stats.get("avg_duration", 0),
                api_stats.get("max_duration", 0)
            ]
            
            fig = go.Figure(data=[
                go.Bar(
                    x=["ìµœì†Œ", "í‰ê· ", "ìµœëŒ€"],
                    y=response_times,
                    marker_color=['green', 'blue', 'red']
                )
            ])
            
            fig.update_layout(
                title="API ì‘ë‹µ ì‹œê°„ (ì´ˆ)",
                yaxis_title="ì‹œê°„ (ì´ˆ)",
                height=300
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # API details
            with st.expander("ğŸ“Š API ìƒì„¸ ì •ë³´"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**ì´ í˜¸ì¶œ ìˆ˜:** {api_stats.get('total_calls', 0)}íšŒ")
                    st.write(f"**ì„±ê³µë¥ :** {api_stats.get('success_rate', 0):.1f}%")
                with col2:
                    st.write(f"**í‰ê·  ì‘ë‹µì‹œê°„:** {api_stats.get('avg_duration', 0):.2f}ì´ˆ")
                    st.write(f"**ìµœê·¼ 5ë¶„ í˜¸ì¶œ:** {api_stats.get('recent_calls', 0)}íšŒ")
        else:
            st.info("ğŸ“Š API í˜¸ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def render_cache_metrics(self, perf_data: Dict[str, Any]):
        """Render cache performance metrics."""
        st.markdown("#### ğŸ’¨ ìºì‹œ ì„±ëŠ¥")
        
        cache_stats = perf_data.get("cache_stats", {})
        
        if cache_stats and "error" not in cache_stats:
            # Cache hit rate pie chart
            hit_rate = cache_stats.get("hit_rate", 0)
            miss_rate = 100 - hit_rate
            
            fig = go.Figure(data=[go.Pie(
                labels=['ìºì‹œ ì ì¤‘', 'ìºì‹œ ë¯¸ìŠ¤'],
                values=[hit_rate, miss_rate],
                hole=.3,
                marker_colors=['green', 'red']
            )])
            
            fig.update_layout(
                title="ìºì‹œ ì ì¤‘ë¥ ",
                height=300
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Cache details
            with st.expander("ğŸ“Š ìºì‹œ ìƒì„¸ ì •ë³´"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**ì´ ì—”íŠ¸ë¦¬:** {cache_stats.get('total_entries', 0)}ê°œ")
                    st.write(f"**ìœ íš¨ ì—”íŠ¸ë¦¬:** {cache_stats.get('valid_entries', 0)}ê°œ")
                with col2:
                    st.write(f"**ìºì‹œ í¬ê¸°:** {cache_stats.get('cache_size_mb', 0):.2f}MB")
                    st.write(f"**ì ì¤‘ë¥ :** {hit_rate:.1f}%")
        else:
            st.info("ğŸ“Š ìºì‹œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def render_ui_metrics(self, perf_data: Dict[str, Any]):
        """Render UI performance metrics."""
        st.markdown("#### ğŸ–¥ï¸ UI ì„±ëŠ¥")
        
        ui_stats = perf_data.get("ui_performance", {})
        
        if ui_stats and "error" not in ui_stats:
            # UI render time metrics
            render_times = {
                "í‰ê·  ë Œë”ë§ ì‹œê°„": ui_stats.get("avg_render_time", 0),
                "ìµœëŒ€ ë Œë”ë§ ì‹œê°„": ui_stats.get("max_render_time", 0),
                "ìµœì†Œ ë Œë”ë§ ì‹œê°„": ui_stats.get("min_render_time", 0)
            }
            
            fig = go.Figure(data=[
                go.Bar(
                    x=list(render_times.keys()),
                    y=list(render_times.values()),
                    marker_color=['blue', 'red', 'green']
                )
            ])
            
            fig.update_layout(
                title="UI ë Œë”ë§ ì‹œê°„ (ì´ˆ)",
                yaxis_title="ì‹œê°„ (ì´ˆ)",
                height=300
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # UI details
            with st.expander("ğŸ“Š UI ìƒì„¸ ì •ë³´"):
                st.write(f"**ì´ ë Œë”ë§ íšŸìˆ˜:** {ui_stats.get('total_renders', 0)}íšŒ")
                st.write(f"**í‰ê·  ë Œë”ë§ ì‹œê°„:** {ui_stats.get('avg_render_time', 0):.3f}ì´ˆ")
                
                if ui_stats.get('avg_render_time', 0) > 0.5:
                    st.warning("âš ï¸ UI ë Œë”ë§ì´ ëŠë¦½ë‹ˆë‹¤. ìµœì í™”ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ“Š UI ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def render_recommendations(self, perf_data: Dict[str, Any]):
        """Render performance optimization recommendations."""
        recommendations = perf_data.get("recommendations", [])
        
        if recommendations:
            st.markdown("#### ğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­")
            
            for i, recommendation in enumerate(recommendations, 1):
                st.info(f"**{i}.** {recommendation}")
        else:
            st.success("âœ… í˜„ì¬ ì‹œìŠ¤í…œ ì„±ëŠ¥ì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
    
    def render_control_panel(self):
        """Render performance control panel."""
        st.markdown("---")
        st.markdown("#### ğŸ›ï¸ ì„±ëŠ¥ ì œì–´íŒ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            if st.button("ğŸ§¹ ë©”ëª¨ë¦¬ ìµœì í™”", help="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì í™”í•©ë‹ˆë‹¤"):
                with st.spinner("ë©”ëª¨ë¦¬ ìµœì í™” ì¤‘..."):
                    result = performance_monitor.memory_optimizer.optimize_memory(force=True)
                    if result["optimized"]:
                        st.success(f"âœ… {result['memory_saved_mb']:.1f}MB ë©”ëª¨ë¦¬ ì ˆì•½")
                    else:
                        st.info("â„¹ï¸ ìµœì í™”ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        
        with col2:
            if st.button("ğŸ—‘ï¸ ìºì‹œ ì •ë¦¬", help="API ì‘ë‹µ ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤"):
                performance_monitor.api_optimizer.response_cache.clear()
                st.success("âœ… ìºì‹œê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤")
        
        with col3:
            if st.button("ğŸ“Š ì„±ëŠ¥ ë¦¬í¬íŠ¸", help="ìƒì„¸í•œ ì„±ëŠ¥ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"):
                self.show_detailed_report()
        
        with col4:
            monitoring_status = performance_monitor.monitoring_active
            if monitoring_status:
                if st.button("â¹ï¸ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€", help="ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ì¤‘ì§€í•©ë‹ˆë‹¤"):
                    from utils.performance_optimizer import stop_performance_monitoring
                    stop_performance_monitoring()
                    st.success("âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤")
                    st.rerun()
            else:
                if st.button("â–¶ï¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘", help="ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤"):
                    from utils.performance_optimizer import start_performance_monitoring
                    start_performance_monitoring()
                    st.success("âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤")
                    st.rerun()
    
    def show_detailed_report(self):
        """Show detailed performance report."""
        perf_data = get_performance_dashboard()
        
        with st.expander("ğŸ“‹ ìƒì„¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸", expanded=True):
            st.json(perf_data)
    
    def render_compact_performance_widget(self):
        """Render a compact performance widget for sidebar."""
        st.markdown("### ğŸ“Š ì„±ëŠ¥ ìƒíƒœ")
        
        perf_data = get_performance_dashboard()
        
        if "error" not in perf_data:
            memory_info = perf_data.get("memory", {})
            current_memory = memory_info.get("current_mb", 0)
            threshold_memory = memory_info.get("threshold_mb", config.MAX_MEMORY_USAGE_MB)
            memory_percent = (current_memory / threshold_memory) * 100
            
            # Memory usage progress bar
            st.write("ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰")
            st.progress(min(memory_percent / 100, 1.0))
            st.caption(f"{current_memory:.0f}MB / {threshold_memory:.0f}MB ({memory_percent:.1f}%)")
            
            # API performance
            api_stats = perf_data.get("api_performance", {})
            if "error" not in api_stats:
                success_rate = api_stats.get("success_rate", 0)
                st.write("ğŸ”— API ì„±ê³µë¥ ")
                st.progress(success_rate / 100)
                st.caption(f"{success_rate:.1f}%")
            
            # Cache hit rate
            cache_stats = perf_data.get("cache_stats", {})
            if "error" not in cache_stats:
                hit_rate = cache_stats.get("hit_rate", 0)
                st.write("ğŸ’¨ ìºì‹œ ì ì¤‘ë¥ ")
                st.progress(hit_rate / 100)
                st.caption(f"{hit_rate:.1f}%")
        else:
            st.warning("ì„±ëŠ¥ ë°ì´í„° ì—†ìŒ")


def create_performance_dashboard_ui() -> PerformanceDashboardUI:
    """
    Factory function to create PerformanceDashboardUI instance.
    
    Returns:
        PerformanceDashboardUI: Configured UI instance
    """
    return PerformanceDashboardUI()